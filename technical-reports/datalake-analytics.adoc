---
permalink: technical-reports/datalake-analytics.html 
sidebar: sidebar 
keywords: data lake, on-premises, analytics, storagegrid, object 
summary: 이 보고서에서는 StorageGRID의 빅데이터 분석을 다룹니다. 
---
= NetApp StorageGRID 및 빅데이터 분석
:hardbreaks:
:allow-uri-read: 
:icons: font
:imagesdir: ../media/




== NetApp StorageGRID 사용 사례

NetApp StorageGRID 오브젝트 스토리지 솔루션은 확장성, 데이터 가용성, 보안 및 고성능을 제공합니다. 모든 규모와 다양한 산업 분야의 조직이 광범위한 사용 사례에 StorageGRID S3를 사용합니다. 몇 가지 일반적인 시나리오를 살펴보겠습니다.

* 빅 데이터 분석: * StorageGRID S3는 기업에서 Apache Spark, Splunk Smartstore 및 Dremio와 같은 도구를 사용하여 분석을 위해 대량의 정형 및 비정형 데이터를 저장하는 데이터 레이크로 자주 사용됩니다.

* 데이터 계층화: * NetApp 고객은 ONTAP의 FabricPool 기능을 사용하여 고성능 로컬 계층 간에 데이터를 자동으로 StorageGRID로 이동합니다. 계층화하면 콜드 데이터를 저렴한 오브젝트 스토리지에서 즉시 사용 가능한 상태로 유지하면서 고가의 플래시 스토리지를 핫 데이터용으로 확보할 수 있습니다. 따라서 성능과 비용 절감 효과가 극대화됩니다.

* 데이터 백업 및 재해 복구: * 기업에서는 StorageGRID S3를 안정적이고 비용 효율적인 솔루션으로 사용하여 중요한 데이터를 백업하고 재해 발생 시 복구할 수 있습니다.

* 응용 프로그램용 데이터 저장: * StorageGRID S3는 응용 프로그램용 스토리지 백엔드로 사용할 수 있으므로 개발자가 파일, 이미지, 비디오 및 기타 유형의 데이터를 쉽게 저장하고 검색할 수 있습니다.

* 콘텐츠 전송: * StorageGRID S3를 사용하여 정적 웹 사이트 콘텐츠, 미디어 파일 및 소프트웨어 다운로드를 전 세계 사용자에게 저장하고 제공할 수 있으며, StorageGRID의 지리적 분산 및 글로벌 네임스페이스를 활용하여 빠르고 안정적인 콘텐츠 전송을 수행할 수 있습니다.

* 데이터 계층화: * NetApp 고객은 ONTAP FabricPool 기능을 사용하여 고성능 로컬 계층 간에 데이터를 자동으로 StorageGRID로 이동합니다. 계층화하면 콜드 데이터를 저렴한 오브젝트 스토리지에서 즉시 사용 가능한 상태로 유지하면서 고가의 플래시 스토리지를 핫 데이터용으로 확보할 수 있습니다. 따라서 성능과 비용 절감 효과가 극대화됩니다.

* 데이터 아카이브: * StorageGRID는 다양한 스토리지 유형을 제공하고 공용 장기 저비용 스토리지 옵션에 대한 계층화를 지원하며, 규정 준수 또는 기간별 목적으로 보존해야 하는 데이터의 보관 및 장기 보존에 이상적인 솔루션입니다.

* 오브젝트 스토리지 사용 사례 *

image:datalake-analytics/image1.png["StorageGRID 사용 사례 다이어그램, 폭 = 396, 높이 = 394"]

위 중 빅 데이터 분석은 최상위 사용 사례 중 하나이며 사용량이 증가하고 있습니다.



== 데이터 레이크에 StorageGRID를 사용해야 하는 이유

* 협업 증가 - 업계 표준 API 액세스를 지원하는 대규모 공유 멀티 사이트 멀티 테넌시
* 운영 비용 절감 - 자동 복구, 자동화된 단일 스케일아웃 아키텍처를 통해 운영 간소화
* 확장성 - 기존 Hadoop 및 데이터 웨어하우스 솔루션과 달리 StorageGRID S3 오브젝트 스토리지는 스토리지를 컴퓨팅과 데이터와 분리하므로 기업이 필요에 따라 스토리지 요구사항을 확장할 수 있습니다.
* 내구성 및 안정성 - StorageGRID는 99.9999999%의 내구성을 제공하여 저장된 데이터가 데이터 손실에 대한 저항성이 높습니다. 또한 고가용성을 제공하여 데이터에 항상 액세스할 수 있도록 보장합니다.
* 보안-StorageGRID는 암호화, 액세스 제어 정책, 데이터 라이프사이클 관리, 오브젝트 잠금 및 버전 관리와 같은 다양한 보안 기능을 제공하여 S3 버킷에 저장된 데이터를 보호합니다


* StorageGRID S3 데이터 레이크 *

image:datalake-analytics/image2.png["StorageGRID 데이터 레이크 예, width=614, height=345"]



== S3 오브젝트 스토리지에서 가장 잘 작동하는 데이터 웨어하우스 또는 데이터 레이크가 있습니다

NetApp는 Hive, Delta Lake 및 Dremio 등 3개의 데이터 웨어하우스/호수 하우스 에코시스템을 통해 StorageGRID의 벤치마크를 수행했습니다. https://www.dremio.com/wp-content/uploads/2023/02/apache-iceberg-TDG_ER1.pdf?aliId=eyJpIjoieDRUYjFKN2ZMbXhTRnFRWCIsInQiOiJIUUw0djJsWnlJa21iNUsyQURRalNnPT0ifQ%253D%253D["아파치 아이스버그: 확실한 가이드"] 데이터 웨어하우스 및 데이터 레이크 하우스에 대한 간략한 소개와 이 두 아키텍처의 장점 포함

* 벤치마크 도구 - TPC-DS - https://www.tpc.org/tpcds/[]
* 빅 데이터 에코시스템
+
** VM 5개로 구성된 클러스터, 각각 128G RAM 및 24개의 vCPU, 시스템 디스크용 SSD 스토리지
** Hive 3.1.3 포함 Hadoop 3.3.5(이름 노드 1개 + 데이터 노드 4개)
** Spark 3.0.0(마스터 1명 + 작업자 4명) 및 Hadoop 3.3.5 지원 델타 레이크
** Dremio v23(마스터 1개 + 실행자 4개)


* 오브젝트 스토리지
+
** NetApp ® StorageGRID ® 11.6(SG6060 + SG1000 로드 밸런서 3개 포함
** 오브젝트 보호 - 복사본 2개


* 데이터베이스 크기 1000GB
* 각 쿼리 테스트에 대해 일관된 결과를 얻기 위해 3개 에코시스템에서 캐시를 모두 사용할 수 없습니다.


TPC-DS에는 쿼리 벤치마킹을 위한 99개의 복잡한 SQL 쿼리가 포함되어 있습니다. 전체 시간(분)을 측정하여 99개의 쿼리를 모두 완료했으며 결과를 분석하기 위한 S3 요청의 유형과 수를 세분화하여 더 깊이 있게 조사했습니다. 아래의 첫 번째 표는 99개의 모든 쿼리의 총 기간을 보여 주며 두 번째 표는 각 에코시스템에서 StorageGRID로 전송된 S3 요청의 수와 유형을 요약한 것입니다.

* TPC-DS 쿼리 결과 *

[cols="35%,20%,23%,22%"]
|===
| 에코시스템 | 하이브 | 델타 레이크 | 드리미오 


| 지원합니다 | NetApp (영어) StorageGRID (영어 | NetApp (영어) StorageGRID (영어 | NetApp (영어) StorageGRID (영어 


| 드라이브 유형입니다 | HDD | HDD | HDD 


| 표 형식 | 마루 | 마루 | 마루 1 


| 데이터베이스 크기 | 1000g | 1000g | 1000g 


| TPCDS 99 쿼리 +
총 시간(분) | 1084 - 2도 | 55 | 47 
|===
파케(Parquet)와 아이스버그(Iceberg) 테이블 형식을 모두 테스트한 결과도 이와 유사합니다.

2. 조회 번호 72를 완료할 수 없습니다.

* TPC-DS 쿼리 - S3 요청 분석 *

[cols="24%,24%,27%,25%"]
|===
| S3 요청 | 하이브 | 델타 레이크 | 드리미오 


| 가져오기 | 1,117,184 | 2,074,610 | 4,414,227 


| 관찰: +
모든 제품군 GET | 80% 범위 32MB 객체에서 2KB ~ 2MB, 초당 50 ~ 100회의 요청 | 73% 범위는 32MB 개체에서 100KB 미만으로, 초당 1000 - 1400개의 요청 수입니다 | 90% 1M 바이트 범위는 256MB 객체, 초당 2000-2300개 요청에서 가져옵니다 


| 개체 나열 | 312,053입니다 | 24,158입니다 | 240 


| 머리 +
(존재하지 않는 객체) | 156,027 | 12,103 | 192 


| 머리 +
(존재하는 객체) | 982,126 | 922,732 | 1,845 


| 총 요청 수입니다 | 2,567,390입니다 | 3,033,603입니다 | 4,416,504입니다 
|===
첫 번째 테이블에서, 우리는 델타 호수와 Dremio가 Hive보다 훨씬 더 빠르다는 것을 볼 수 있습니다. 두 번째 표에서 Hive는 많은 S3 목록 오브젝트 요청을 전송했습니다. 이 요청은 모든 오브젝트 스토리지 플랫폼에서 일반적으로 느리며, 특히 많은 오브젝트가 포함된 버킷을 다룰 경우 매우 느립니다. 따라서 전체 쿼리 기간이 크게 증가합니다. 또 다른 관찰은 Dremio가 Hive에서 초당 50-100개의 요청을 처리하는 데 비해 초당 2,000-2,300개의 요청을 동시에 보낼 수 있다는 것입니다. Hive 및 Hadoop S3A는 표준 파일 시스템을 모방하여 S3 오브젝트 스토리지에 Hive 느림 효과를 제공합니다.

Hive 또는 Spark와 함께 Hadoop(HDFS 또는 S3 오브젝트 스토리지)을 사용하려면 Hadoop 및 Hive/Spark와 각 서비스의 설정이 상호 작용하는 방법에 대한 폭넓은 지식이 필요합니다. 이러한 두 서비스의 설정이 1,000개 이상인 경우입니다. 설정은 서로 관련이 있는 경우가 매우 많으며 단독으로 변경할 수 없습니다. 사용할 설정과 값의 최적 조합을 찾기 위해서는 엄청난 시간과 노력이 필요합니다.

Dremio는 완벽한 Apache Arrow를 사용하여 쿼리 성능을 획기적으로 향상하는 데이터 레이크 엔진입니다. Apache Arrow는 효율적인 데이터 공유와 빠른 분석을 위해 표준화된 원주 메모리 형식을 제공합니다. Arrow는 데이터 serialization 및 deserialization의 필요성을 제거하여 복잡한 데이터 프로세스와 시스템 간의 성능 및 상호 운용성을 향상시키도록 설계된 언어 독립적 접근 방식을 사용합니다.

Dremio의 성능은 주로 Dremio 클러스터의 컴퓨팅 성능에 의해 좌우됩니다. Dremio는 S3 오브젝트 스토리지 연결에 Hadoop의 S3A 커넥터를 사용하지만 Hadoop은 필요하지 않으며 대부분의 Hadoop의 fs.s3a 설정은 Dremio에서 사용되지 않습니다. 따라서 다양한 Hadoop s3a 설정을 배우고 테스트하는 데 시간을 들이지 않고도 Dremio 성능을 손쉽게 튜닝할 수 있습니다.

이러한 벤치마크 결과에서 알 수 있듯이 S3 기반 워크로드에 최적화된 빅데이터 분석 시스템이 주요 성능 요인이라는 결론을 내릴 수 있습니다. Dremio는 쿼리 실행을 최적화하고, 메타데이터를 효율적으로 사용하며, S3 데이터에 대한 원활한 액세스를 제공하므로 S3 스토리지로 작업할 때 Hive에 비해 성능이 향상됩니다. 이를 참조하십시오 https://docs.netapp.com/us-en/storagegrid-enable/tools-apps-guides/configure-dremio-storagegrid.html["페이지"] StorageGRID를 사용하여 Dremio S3 데이터 소스를 구성합니다.

아래 링크를 방문하여 StorageGRID와 Dremio가 함께 작동하여 현대적이고 효율적인 데이터 레이크 인프라를 제공하는 방법과 NetApp가 Hive+ HDFS에서 Dremio+ StorageGRID로 마이그레이션하여 빅데이터 분석 효율성을 획기적으로 개선한 방법에 대해 자세히 알아보십시오.

* https://www.netapp.tv/details/31426?mcid=02148179640195118863901007338453703701["NetApp StorageGRID로 빅데이터의 성능을 향상하십시오"]
* https://www.netapp.com/media/80932-SB-4236-StorageGRID-Dremio.pdf["StorageGRID 및 Dremio를 사용하는 현대적이고 강력하고 효율적인 데이터 레이크 인프라"]
* https://youtu.be/Y57Gyj4De2I?si=nwVG5ohCj93TggKS["NetApp이 제품 분석을 통해 고객 경험을 재정의하는 방법"]

